{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RAG answer quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import dotenv\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "azure_credential = azure.identity.DefaultAzureCredential()\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"gptkbindex\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answer for a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A product manager is responsible for leading the product management team, developing and implementing product strategies, monitoring industry trends, collaborating with internal teams, developing pricing strategies, analyzing product performance, and identifying areas for improvement. They must have a bachelor's degree in business, engineering, or a related field, at least 5 years of experience in product management, and a proven track record of successful product launches. [role_library.pdf#page=29]\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What does a product manager do?\"\n",
    "user_question_vector = get_embedding(user_question)\n",
    "\n",
    "r = search_client.search(\n",
    "        user_question,\n",
    "        top=5, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"embedding\")],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\\n\".join([f\"[{doc['sourcepage']}]: {doc['content']}\\n\" for doc in r])\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Assistant helps company employees questions about the employee handbook. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below.\n",
    "Each source has a name followed by colon and the actual information, include the source name for each fact you use.\n",
    "Use square brackets to reference the source, for example [info1.txt].\n",
    "\"\"\"\n",
    "USER_MESSAGE = user_question + \"\\nSources: \" + sources\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the answer quality\n",
    "\n",
    "We can use the `promptflow-evals` package to run GPT-based evaluators on the RAG responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt_relevance': 5.0}\n",
      "{'gpt_groundedness': 5.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.evals.evaluators import GroundednessEvaluator, RelevanceEvaluator\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    ")\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    question=user_question,\n",
    "    answer=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(relevance_score)\n",
    "\n",
    "groundedness_score = groundedness_eval(\n",
    "    answer=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(groundedness_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
